{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1millionwomentotech SummerOfCode\n",
    "\n",
    "## Intro to AI: Week 4 Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baby_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9472fea96f92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaby_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'baby_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(baby_train[50000]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "text = baby_train[50000]['reviewText']\n",
    "for s in sent_tokenize(text):\n",
    "    print(s)\n",
    "    print(sia.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sia_features(dataset):\n",
    "    \"\"\"For each review text in the dataset, extract:\n",
    "       (1) the mean positive sentiment over all sentences\n",
    "       (2) the mean neutral sentiment over all sentences\n",
    "       (3) the mean negative sentiment over all sentences\n",
    "       (4) the maximum positive sentiment over all sentences\n",
    "       (5) the maximum neutral sentiment over all sentences\n",
    "       (6) the maximum negative sentiment over all sentences\"\"\"\n",
    "    feat_matrix = numpy.empty((len(dataset), 6))\n",
    "    for i in range(len(dataset)):\n",
    "        sentences = sent_tokenize(dataset[i]['reviewText'])\n",
    "        nsent = len(sentences)\n",
    "        if nsent:\n",
    "            sentence_polarities = numpy.empty((nsent, 3))\n",
    "            for j in range(nsent):\n",
    "                polarity = sia.polarity_scores(sentences[j])\n",
    "                sentence_polarities[j, 0] = polarity['pos']\n",
    "                sentence_polarities[j, 1] = polarity['neu']\n",
    "                sentence_polarities[j, 2] = polarity['neg']\n",
    "            feat_matrix[i, 0:3] = numpy.mean(sentence_polarities, axis=0) # mean over the columns\n",
    "            feat_matrix[i, 3:6] = numpy.max(sentence_polarities, axis=0) # maximum over the columns\n",
    "        else:\n",
    "            feat_matrix[i, 0:6] = 0.0\n",
    "    return feat_matrix\n",
    "\n",
    "sia_tr = sia_features(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmat = numpy.arange(12.).reshape((3, 4))\n",
    "print(testmat)\n",
    "print(numpy.max(testmat, axis=0))\n",
    "print(numpy.mean(testmat, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_features(dataset):\n",
    "    \"\"\"Add two features:\n",
    "       (1) length of review (in thousands of characters) - truncate at 2,500\n",
    "       (2) percentage of exclamation marks (in %)\"\"\"\n",
    "    feat_matrix = numpy.empty((len(dataset), 2))\n",
    "    for i in range(len(dataset)):\n",
    "        text = dataset[i]['reviewText']\n",
    "        feat_matrix[i, 0] = len(text) / 1000.\n",
    "        if text:\n",
    "            feat_matrix[i, 1] = 100. * text.count('!') / len(text)\n",
    "        else:\n",
    "            feat_matrix[i, 1] = 0.0\n",
    "    feat_matrix[feat_matrix>2.5] = 2.5\n",
    "    return feat_matrix\n",
    "\n",
    "len_tr = len_features(baby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_neg.shape, sia_tr.shape, len_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = numpy.concatenate((X_train_neg, sia_tr, len_tr), axis=1) # stack horizontally\n",
    "lreg_augmented = LinearRegression().fit(X_train_augmented, Y_train)\n",
    "pred_train_augmented = lreg_augmented.predict(X_train_augmented)\n",
    "mae_train_augmented = mean_absolute_error(pred_train_augmented, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_augmented = RandomForestRegressor().fit(X_train_augmented, Y_train)\n",
    "rfpred_train_augmented = rf_augmented.predict(X_train_augmented)\n",
    "mae_train_rf_augmented = mean_absolute_error(rfpred_train_augmented, Y_train)\n",
    "print(\"For the RF, it is %f stars\" % mae_train_rf_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_neg = dataset_to_matrix_with_neg(baby_valid)\n",
    "sia_valid = sia_features(baby_valid)\n",
    "len_valid = len_features(baby_valid)\n",
    "X_valid_augmented = numpy.concatenate((X_valid_neg, sia_valid, len_valid), axis=1)\n",
    "pred_valid_augmented = lreg_augmented.predict(X_valid_augmented)\n",
    "pred_valid_rf_augmented = rf_augmented.predict(X_valid_augmented)\n",
    "mae_valid_augmented = mean_absolute_error(pred_valid_augmented, Y_valid)\n",
    "print(\"On the validation set, we get %f error for the linear regression\" % mae_valid_augmented)\n",
    "mae_valid_rf_augmented = mean_absolute_error(pred_valid_rf_augmented, Y_valid)\n",
    "print(\"And %f for the random forest regression\" % mae_valid_rf_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baby_train[50000]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "text = baby_train[50000]['reviewText']\n",
    "for s in sent_tokenize(text):\n",
    "    print(s)\n",
    "    print(sia.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sia_features(dataset):\n",
    "    \"\"\"For each review text in the dataset, extract:\n",
    "    (1) mean positive sentiment over all sentences\n",
    "    (2) mean neutral sentiment over all sentences\n",
    "    (3) mean negative sentiment over all sentences\n",
    "    (4) maximum positive sentiment over all sentences\n",
    "    (5) maximum neutral sentiment over all sentences\n",
    "    (6) maximum negative sentiment over all sentences\n",
    "    \"\"\"\n",
    "    feat_matrix = numpy.empty((len(dataset), 6))\n",
    "    for i in range(len(dataset)):\n",
    "        sentences = sent_tokenize(dataset[i]['reviewText'])\n",
    "        nsent = len(sentences)\n",
    "        if nsent:\n",
    "            sentence_polarities = numpy.empty((nsent, 3))\n",
    "            for j in range(nsent):\n",
    "                polarity = sia.polarity_scores(sentences[j])\n",
    "                sentence_polarities[j, 0] = polarity['pos']\n",
    "                sentence_polarities[j, 1] = polarity['neu']\n",
    "                sentence_polarities[j, 2] = polarity['neg']\n",
    "            feat_matrix[i, 0:3] = numpy.mean(sentence_polarities, axis = 0) # mean over the columns\n",
    "            feat_matrix[i, 3:6] = numpy.max(sentence_polarities, axis = 0) # maximum over the columns\n",
    "        else:\n",
    "            feat_matrix[i, 0:6] = 0.0\n",
    "    return feat_matrix    \n",
    "            \n",
    "sia_tr = sia_features(baby_train)\n",
    "print(sia_tr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmat = numpy.arange(12.).reshape((3,4))\n",
    "print(testmat)\n",
    "print(numpy.max(testmat, axis = 0))\n",
    "print(numpy.mean(testmat, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework - required for Certification\n",
    "\n",
    "def len_features(dataset):\n",
    "    \"\"\"Add two features:\n",
    "    (1) length of review (in thousands of character) - truncate at 2,500\n",
    "    (2) percentage of exclamation marks (in %)\n",
    "    \"\"\"\n",
    "\n",
    "len_tr = len_features(baby_train)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_neg.shape, sia_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack horizontally\n",
    "X_train_augmented = numpy.concatenate( (X_train_neg, sia_tr), axis = 1)\n",
    "lreg_augmented = LinearRegression().fit(X_train_augmented, Y_train)\n",
    "pred_train_augmented = lreg_augmented.predict(X_train_augmented)\n",
    "mae_train_augmented = mean_absolute_error(pred_train_augmented, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f starts\" % mae_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf_augmented = RandomForestRegressor().fit(X_train_augmented, Y_train)\n",
    "rfpred_train_augmented = rf_augmented.predict(X_train_augmented)\n",
    "mae_train_rf_augmented = mean_absolute_error(rfpred_train_augmented, Y_train)\n",
    "print(\"For the RF, MAE is %f stars\" % mae_train_rf_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_neg = dataset_to_matrix_with_neg(baby_valid)\n",
    "sia_valid = sia_features(baby_valid)\n",
    "# len_valid = \n",
    "X_valid_augmented = numpy.concatenate((X_valid_neg, sia_valid), axis = 1)\n",
    "pred_valid_augmented =\n",
    "pred_valid_rfaugmented =\n",
    "\n",
    "mae_valid_augmented = \n",
    "mae_valid_rfaugmented ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework for certification\n",
    "\n",
    "Refactor the code above:\n",
    "- \"Be lazy. Not just lazy but proactively, agressively lazy.\" Remove duplication.\n",
    "- create a single function that takes in data and spits out all success metrics across all of your algos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go from here?\n",
    "\n",
    "\n",
    "- unigrams (NLTK)\n",
    "- word vector (gensim, [glove](https://nlp.stanford.edu/projects/glove/), word2vec)\n",
    "- recurrent neural net\n",
    "- convolutional neural net\n",
    "\n",
    "https://www.oreilly.com/learning/perform-sentiment-analysis-with-lstms-using-tensorflow\n",
    "\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "\n",
    "https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
